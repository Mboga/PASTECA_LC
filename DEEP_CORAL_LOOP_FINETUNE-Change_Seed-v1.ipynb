{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([274278,  65893, 212318, 284540, 522779, 237628,  40964],\n",
      "      dtype=int64))\n",
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([155925,  36584, 308603, 322332, 378916, 321349, 114691],\n",
      "      dtype=int64))\n",
      "epoch number 1\n",
      "----------\n",
      "epoch number 2\n",
      "----------\n",
      "epoch number 3\n",
      "----------\n",
      "epoch number 4\n",
      "----------\n",
      "epoch number 5\n",
      "----------\n",
      "epoch number 6\n",
      "----------\n",
      "epoch number 7\n",
      "----------\n",
      "epoch number 8\n",
      "----------\n",
      "epoch number 9\n",
      "----------\n",
      "epoch number 10\n",
      "----------\n",
      "epoch number 11\n",
      "----------\n",
      "epoch number 12\n",
      "----------\n",
      "epoch number 13\n",
      "----------\n",
      "epoch number 14\n",
      "----------\n",
      "epoch number 15\n",
      "----------\n",
      "epoch number 16\n",
      "----------\n",
      "epoch number 17\n",
      "----------\n",
      "epoch number 18\n",
      "----------\n",
      "epoch number 19\n",
      "----------\n",
      "epoch number 20\n",
      "----------\n",
      "epoch number 21\n",
      "----------\n",
      "epoch number 22\n",
      "----------\n",
      "epoch number 23\n",
      "----------\n",
      "epoch number 24\n",
      "----------\n",
      "epoch number 25\n",
      "----------\n",
      "epoch number 26\n",
      "----------\n",
      "epoch number 27\n",
      "----------\n",
      "epoch number 28\n",
      "----------\n",
      "epoch number 29\n",
      "----------\n",
      "epoch number 30\n",
      "----------\n",
      "epoch number 31\n",
      "----------\n",
      "epoch number 32\n",
      "----------\n",
      "epoch number 33\n",
      "----------\n",
      "epoch number 34\n",
      "----------\n",
      "epoch number 35\n",
      "----------\n",
      "epoch number 36\n",
      "----------\n",
      "epoch number 37\n",
      "----------\n",
      "epoch number 38\n",
      "----------\n",
      "epoch number 39\n",
      "----------\n",
      "epoch number 40\n",
      "----------\n",
      "epoch number 41\n",
      "----------\n",
      "epoch number 42\n",
      "----------\n",
      "epoch number 43\n",
      "----------\n",
      "epoch number 44\n",
      "----------\n",
      "epoch number 45\n",
      "----------\n",
      "epoch number 46\n",
      "----------\n",
      "epoch number 47\n",
      "----------\n",
      "epoch number 48\n",
      "----------\n",
      "epoch number 49\n",
      "----------\n",
      "epoch number 50\n",
      "----------\n",
      "training complete in 2.30\n",
      "created path\n",
      "created path\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "Finished testing after 2.26 mins\n",
      "created path\n",
      "Tile 1 of 8\n",
      "Tile 2 of 8\n",
      "Tile 3 of 8\n",
      "Tile 4 of 8\n",
      "Tile 5 of 8\n",
      "Tile 6 of 8\n",
      "Tile 7 of 8\n",
      "Tile 8 of 8\n",
      "created path\n",
      "created path\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "Finished testing after 1.35 mins\n",
      "created path\n",
      "Tile 1 of 5\n",
      "Tile 2 of 5\n",
      "Tile 3 of 5\n",
      "Tile 4 of 5\n",
      "Tile 5 of 5\n",
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([1726226,  652674,  930814, 1242347, 2285978, 1126192,  227769],\n",
      "      dtype=int64))\n",
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([ 788197,  306840, 1281379, 1927165, 2103589, 1385244,  399586],\n",
      "      dtype=int64))\n",
      "epoch number 1\n",
      "----------\n",
      "epoch number 2\n",
      "----------\n",
      "epoch number 3\n",
      "----------\n",
      "epoch number 4\n",
      "----------\n",
      "epoch number 5\n",
      "----------\n",
      "epoch number 6\n",
      "----------\n",
      "epoch number 7\n",
      "----------\n",
      "epoch number 8\n",
      "----------\n",
      "epoch number 9\n",
      "----------\n",
      "epoch number 10\n",
      "----------\n",
      "epoch number 11\n",
      "----------\n",
      "epoch number 12\n",
      "----------\n",
      "epoch number 13\n",
      "----------\n",
      "epoch number 14\n",
      "----------\n",
      "epoch number 15\n",
      "----------\n",
      "epoch number 16\n",
      "----------\n",
      "epoch number 17\n",
      "----------\n",
      "epoch number 18\n",
      "----------\n",
      "epoch number 19\n",
      "----------\n",
      "epoch number 20\n",
      "----------\n",
      "epoch number 21\n",
      "----------\n",
      "epoch number 22\n",
      "----------\n",
      "epoch number 23\n",
      "----------\n",
      "epoch number 24\n",
      "----------\n",
      "epoch number 25\n",
      "----------\n",
      "epoch number 26\n",
      "----------\n",
      "epoch number 27\n",
      "----------\n",
      "epoch number 28\n",
      "----------\n",
      "epoch number 29\n",
      "----------\n",
      "epoch number 30\n",
      "----------\n",
      "epoch number 31\n",
      "----------\n",
      "epoch number 32\n",
      "----------\n",
      "epoch number 33\n",
      "----------\n",
      "epoch number 34\n",
      "----------\n",
      "epoch number 35\n",
      "----------\n",
      "epoch number 36\n",
      "----------\n",
      "epoch number 37\n",
      "----------\n",
      "epoch number 38\n",
      "----------\n",
      "epoch number 39\n",
      "----------\n",
      "epoch number 40\n",
      "----------\n",
      "epoch number 41\n",
      "----------\n",
      "epoch number 42\n",
      "----------\n",
      "epoch number 43\n",
      "----------\n",
      "epoch number 44\n",
      "----------\n",
      "epoch number 45\n",
      "----------\n",
      "epoch number 46\n",
      "----------\n",
      "epoch number 47\n",
      "----------\n",
      "epoch number 48\n",
      "----------\n",
      "epoch number 49\n",
      "----------\n",
      "epoch number 50\n",
      "----------\n",
      "training complete in 11.39\n",
      "created path\n",
      "created path\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "Finished testing after 2.28 mins\n",
      "created path\n",
      "Tile 1 of 8\n",
      "Tile 2 of 8\n",
      "Tile 3 of 8\n",
      "Tile 4 of 8\n",
      "Tile 5 of 8\n",
      "Tile 6 of 8\n",
      "Tile 7 of 8\n",
      "Tile 8 of 8\n",
      "created path\n",
      "created path\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (8, 1, 256, 256)\n",
      "(8, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "out shape (256, 256, 6)\n",
      "images_patches_1.shape (1, 1, 256, 256)\n",
      "(1, 6, 256, 256)\n",
      "out shape (256, 256, 6)\n",
      "Finished testing after 1.34 mins\n",
      "created path\n",
      "Tile 1 of 5\n",
      "Tile 2 of 5\n",
      "Tile 3 of 5\n",
      "Tile 4 of 5\n",
      "Tile 5 of 5\n",
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([3505661, 1358993, 1842037, 2410210, 4633537, 2192117,  441445],\n",
      "      dtype=int64))\n",
      "(array([-1.,  0.,  1.,  2.,  3.,  4.,  5.]), array([1586157,  599790, 2585761, 3699159, 4402656, 2761277,  749200],\n",
      "      dtype=int64))\n",
      "epoch number 1\n",
      "----------\n",
      "epoch number 2\n",
      "----------\n",
      "epoch number 3\n",
      "----------\n",
      "epoch number 4\n",
      "----------\n",
      "epoch number 5\n",
      "----------\n",
      "epoch number 6\n",
      "----------\n",
      "epoch number 7\n",
      "----------\n",
      "epoch number 8\n",
      "----------\n",
      "epoch number 9\n",
      "----------\n",
      "epoch number 10\n",
      "----------\n",
      "epoch number 11\n",
      "----------\n",
      "epoch number 12\n",
      "----------\n",
      "epoch number 13\n",
      "----------\n",
      "epoch number 14\n",
      "----------\n",
      "epoch number 15\n",
      "----------\n",
      "epoch number 16\n",
      "----------\n",
      "epoch number 17\n",
      "----------\n",
      "epoch number 18\n",
      "----------\n",
      "epoch number 19\n",
      "----------\n",
      "epoch number 20\n",
      "----------\n",
      "epoch number 21\n",
      "----------\n",
      "epoch number 22\n",
      "----------\n",
      "epoch number 23\n",
      "----------\n",
      "epoch number 24\n",
      "----------\n",
      "epoch number 25\n",
      "----------\n",
      "epoch number 26\n",
      "----------\n",
      "epoch number 27\n",
      "----------\n",
      "epoch number 28\n",
      "----------\n",
      "epoch number 29\n",
      "----------\n",
      "epoch number 30\n",
      "----------\n",
      "epoch number 31\n",
      "----------\n",
      "epoch number 32\n",
      "----------\n",
      "epoch number 33\n",
      "----------\n",
      "epoch number 34\n",
      "----------\n",
      "epoch number 35\n",
      "----------\n",
      "epoch number 36\n",
      "----------\n",
      "epoch number 37\n",
      "----------\n",
      "epoch number 38\n",
      "----------\n",
      "epoch number 39\n",
      "----------\n",
      "epoch number 40\n",
      "----------\n",
      "epoch number 41\n",
      "----------\n",
      "epoch number 42\n",
      "----------\n",
      "epoch number 43\n",
      "----------\n",
      "epoch number 44\n",
      "----------\n",
      "epoch number 45\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#import the libraries\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import torchvision\n",
    "#from torchvision import datasets, transforms\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "from torch.utils import data\n",
    "#from torchvision import transforms\n",
    "import itertools\n",
    "from torch.autograd import Variable\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import h5py as h5\n",
    "from osgeo import gdal\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#desktop paths\n",
    "root_path = \"H:/DA_ETH/DRC_BALANCED\"\n",
    "\n",
    "\n",
    "#src_data_dir = root_path + \"/BUKAVU_1957/samples/training_buk_57.hdf5\"\n",
    "#src_data_dir = root_path + \"/GOMA_1947/samples/training_gom_47.hdf5\"\n",
    "#tgt_data_dir = root_path + \"/BUJUMBURA_1957_58_59/samples/training_buj_57.hdf5\"\n",
    "\n",
    "\n",
    "#tgt_data_dir ='H:/DA_ETH/DRC_BALANCED/buj_57_59.hdf5'\n",
    "#src_data_dir = 'H:/POTSDAM/resample/samples/training_potsdam.hdf5'\n",
    "#tgt_data_dir = 'H:/ISPRS2DVAIHINGEN/ISPRS_semantic_labeling_Vaihingen/resample/samples/training_vaihingen.hdf5'\n",
    "\n",
    "'''\n",
    "root_path = \"/work/nmboga/deep_learning\"\n",
    "#src_data_dir = root_path + \"/drc_thesis/training_buk_bld_1m.hdf5\"\n",
    "src_data_dir = root_path + \"/drc_thesis/tile1_128ps_1_bld.hdf5\"    #bukavu 59\n",
    "tgt_data_dir = root_path +\"/drc_thesis/tile1_129patch_size.hdf5\"   #goma 47\n",
    "output_dir = root_path + \"/WEIGHTS/\"\n",
    "'''\n",
    "output_dir = root_path + \"/WEIGHTS/\"\n",
    "loss_folder = root_path+'/FIGURES/loss_seg_pot_vaih.hdf5'\n",
    "#loss_folder = root_path+'/FIGURES/loss_seg_pot_vaih.hdf5'\n",
    "#src_data_dir = root_path + \"/BUKAVU_1959/tile1_128ps_1_bld.hdf5\"\n",
    "#tgt_data_dir = root_path +\"/BUJUMBURA_1957_59/tile1_129ps_2.hdf5\"\n",
    "#w8_fname = 'H:/DA_ETH/DRC_BALANCED/WEIGHTS/gom_src_2400.hdf5'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#N_CLASSES = 5\n",
    "#IN_CHANNELS = 3\n",
    "\n",
    "N_CLASSES = 6\n",
    "IN_CHANNELS = 1\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "seed = 572\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "#\n",
    "def nulltozero(arr):\n",
    "    arrcopy = np.copy(arr)\n",
    "    low_values_flags = arrcopy > 1 #0.7,0  \n",
    "    arrcopy[low_values_flags]=0\n",
    "    return arrcopy\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0),input.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1,output.size(2))\n",
    "        target = target.view(-1)\n",
    "        return F.cross_entropy(output, target,weight, ignore_index=-1)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def fil_ter(arr_x,arr_y):\n",
    "    '''\n",
    "    exclude patches with non-building class\n",
    "    '''\n",
    "    x_tr = []\n",
    "    y_tr = []\n",
    "    for i in range(arr_y.shape[0]):\n",
    "        if np.max(nulltozero(arr_y[i]))==0:\n",
    "            pass\n",
    "        else:\n",
    "            #np.max(nulltozero(y_train[i]))==1:\n",
    "            x_tr.append(arr_x[i])\n",
    "            y_tr.append(arr_y[i])\n",
    "    x_tr = np.asarray(x_tr)\n",
    "    y_tr = np.asarray(y_tr)\n",
    "    return x_tr,y_tr\n",
    "\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, archive):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]# subtract one, -1,0,1,2,3,4,5 for softmax\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        #filter the data\n",
    "        self.data,self.labels = fil_ter(self.data,self.labels)\n",
    "        self.data,self.labels = self.data[:5000,:,:,:],self.labels[:5000,:,:,:]\n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], nulltozero(self.labels[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, archive):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:10000,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:10000,:,:128,:128]\n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "        \n",
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, archive):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:10000,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:10000,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        randomlist = random.sample(range(0, 10000), 100)\n",
    "        \n",
    "        self.labels = self.labels[randomlist]\n",
    "        self.data = self.data[randomlist]\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "        \n",
    "def swap_arr(arr):\n",
    "    \"\"\"\n",
    "    #swap axes to that of tf backend (channels last)\n",
    "    \"\"\"\n",
    "    val_1=np.swapaxes(arr,1,3)\n",
    "    val_2=np.swapaxes(val_1,2,3)\n",
    "    return val_2\n",
    "        \n",
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, archive):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:128,:128,:]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:128,:128,:]\n",
    "        \n",
    "        #random.seed(572)\n",
    "        #randomlist = random.sample(range(0, 10000), 100)\n",
    "        \n",
    "        #self.labels = self.labels[randomlist]\n",
    "        #self.data = self.data[randomlist]\n",
    "        print(self.labels.shape)\n",
    "        \n",
    "        self.labels = swap_arr(self.labels)\n",
    "        #print(self.labels.shape)\n",
    "        self.data =swap_arr(self.data)\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "\n",
    "\n",
    "class MyDataset_BK(data.Dataset):\n",
    "    #bukavu\n",
    "    def __init__(self, archive,slice_1 = 1600, slice_2 = 400):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 5195), slice_1)\n",
    "        list_2 = random.sample(range(5196, 7180),slice_2)\n",
    "        list_3 = random.sample(range(7181, 10000), slice_2)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "        \n",
    "class MyDataset_GM(data.Dataset):\n",
    "    #goma 47\n",
    "    def __init__(self, archive,slice_1=1600,slice_2=400):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 3773), slice_1)\n",
    "        list_2 = random.sample(range(3774, 8567),slice_2)\n",
    "        list_3 = random.sample(range(8567, 10000), slice_2)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "class MyDataset_BK(data.Dataset):\n",
    "    #bukavu\n",
    "    def __init__(self, archive,slice_1 = 1600, slice_2 = 400):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 5195), slice_1)\n",
    "        list_2 = random.sample(range(5196, 7180),slice_2)\n",
    "        list_3 = random.sample(range(7181, 10000), slice_2)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()     \n",
    "        \n",
    "# NO RANDOM SAMPLING      \n",
    "class MyDataset_GM(data.Dataset):\n",
    "    #goma 47\n",
    "    def __init__(self, archive,slice_1=1600,slice_2=400):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        #list_1 = random.sample(range(0, 3773), 300)\n",
    "        #list_2 = random.sample(range(3774, 8567),75)\n",
    "        #list_3 = random.sample(range(8567, 10000), 75)\n",
    "        \n",
    "        l_1 = list (range(slice_1))\n",
    "        l_2 = list (range(slice_2))\n",
    "        l_3 = list (range(slice_2))\n",
    "        \n",
    "        #list_2 = list (range(3))\n",
    "        list_1 = [x + 0 for x in l_1] \n",
    "        list_2 = [x + 3774 for x in l_2] \n",
    "        list_3 = [x + 8567 for x in l_3] \n",
    "        \n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "    \n",
    "class MyDataset_BK(data.Dataset):\n",
    "    #bukavu 59\n",
    "    def __init__(self, archive,slice_1=1600,slice_2=400):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        #list_1 = random.sample(range(0, 3773), 300)\n",
    "        #list_2 = random.sample(range(3774, 8567),75)\n",
    "        #list_3 = random.sample(range(8567, 10000), 75)\n",
    "        \n",
    "        l_1 = list (range(slice_1))\n",
    "        l_2 = list (range(slice_2))\n",
    "        l_3 = list (range(slice_2))\n",
    "        \n",
    "        #list_2 = list (range(3))\n",
    "        list_1 = [x + 0 for x in l_1] \n",
    "        list_2 = [x + 5195 for x in l_2] \n",
    "        list_3 = [x + 7180 for x in l_3] \n",
    "        \n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "\n",
    "\n",
    "# random sampling with s        \n",
    "        \n",
    "class MyDataset_GM(data.Dataset):\n",
    "    #goma 47\n",
    "    def __init__(self, archive,slice_3=500,seed_value=10):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 3773), 2000)\n",
    "        list_2 = random.sample(range(3774, 8567),500)\n",
    "        list_3 = random.sample(range(8567, 10000), 500)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        #introduce the sequential seed values\n",
    "        random.seed(seed_value)\n",
    "        list_5 = random.sample(range(0, 3000), slice_3)\n",
    "        self.labels = self.labels[list_5]\n",
    "        self.data = self.data[list_5]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "        \n",
    "class MyDataset_BK(data.Dataset):\n",
    "    #bukavu\n",
    "    def __init__(self, archive, slice_3 = 500, seed_value=10):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 5195), 2000)\n",
    "        list_2 = random.sample(range(5196, 7180),500)\n",
    "        list_3 = random.sample(range(7181, 10000), 500)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        #introduce the sequential seed values\n",
    "        random.seed(seed_value)\n",
    "        list_5 = random.sample(range(0, 3000), slice_3)\n",
    "        self.labels = self.labels[list_5]\n",
    "        self.data = self.data[list_5]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close() \n",
    "\n",
    "'''\n",
    "class MyDataset(data.Dataset):\n",
    "    #bujuumbura\n",
    "    def __init__(self, archive):\n",
    "        self.archive = h5.File(archive, 'r')\n",
    "        self.labels = self.archive['y_train'][:,:,:128,:128]-1# subtract one, -1,0,1,2,3,4,5\n",
    "        self.data = self.archive['X_train'][:,:,:128,:128]\n",
    "        \n",
    "        random.seed(572)\n",
    "        list_1 = random.sample(range(0, 6321), 2000)\n",
    "        list_2 = random.sample(range(6322, 7072), 500)\n",
    "        list_3 = random.sample(range(7073, 10000), 500)\n",
    "\n",
    "        list_4 = list_1+list_2+list_3 \n",
    "        self.labels = self.labels[list_4]\n",
    "        self.data = self.data[list_4]\n",
    "        print(np.unique(self.labels,return_counts=True))\n",
    "        \n",
    "        \n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def close(self):\n",
    "        self.archive.close()\n",
    "'''\n",
    "        \n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "class EncDec(nn.Module):\n",
    "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
    "        super(EncDec,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        #self.bn_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2= nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 1024, kernel_size=3, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(1024, 1024, kernel_size=3, padding = 1)\n",
    "        self.bn_5 = nn.BatchNorm2d(1024)\n",
    "    \n",
    "        #conv transpose layers\n",
    "        self.conv1_t = nn.ConvTranspose2d(1024, 512, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv2_t = nn.ConvTranspose2d(512, 256, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv3_t = nn.ConvTranspose2d(256, 128, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv4_t = nn.ConvTranspose2d(128, 64, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        \n",
    "        #upsampling layers\n",
    "        \n",
    "        self.conv4_1_U = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2_U = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4_U = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1_U = nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2_U = nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3_U = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2_1_U = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2_U = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2_U = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv1_1_U = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2_U = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1_U = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # final output layer\n",
    "        #self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=1, padding = 0)\n",
    "        self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "        # discriminator\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(1024*8*8, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x,alpha):\n",
    "        conv1_d = F.relu(self.conv1_1(x))\n",
    "        conv1_d = self.bn_1(F.relu(self.conv1_2(conv1_d)))\n",
    "        x = self.pool(conv1_d)\n",
    "        #conv1_d = self.pool()\n",
    "        \n",
    "        conv2_d = F.relu(self.conv2_1(x))\n",
    "        conv2_d = self.bn_2(F.relu(self.conv2_2(conv2_d)))\n",
    "        x = self.pool(conv2_d)\n",
    "        \n",
    "        conv3_d = F.relu(self.conv3_1(x))\n",
    "        conv3_d = self.bn_3(F.relu(self.conv3_2(conv3_d)))\n",
    "        x = self.pool(conv3_d)\n",
    "        \n",
    "        conv4_d = F.relu(self.conv4_1(x))\n",
    "        conv4_d = self.bn_4(F.relu(self.conv4_2(conv4_d)))\n",
    "        x = self.pool(conv4_d)\n",
    "        \n",
    "        conv5_d = F.relu(self.conv5_1(x))\n",
    "        conv5_d = self.bn_5(F.relu(self.conv5_2(conv5_d)))\n",
    "        \n",
    "        # x is the output to the domain and scene classfier\n",
    "        \n",
    "        x = F.relu(self.conv1_t(conv5_d))\n",
    "        #merge1 = torch.cat((x,conv4_d),1)\n",
    "        x = F.relu(self.conv4_1_U(x))\n",
    "        x = self.bn_4_U(F.relu(self.conv4_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv2_t(x))\n",
    "        #merge2 = torch.cat((x,conv3_d),1)\n",
    "        x = F.relu(self.conv3_1_U(x))\n",
    "        x = self.bn_3_U(F.relu(self.conv3_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3_t(x))\n",
    "        #merge3 = torch.cat((x,conv2_d),1)\n",
    "        x = F.relu(self.conv2_1_U(x))\n",
    "        x = self.bn_2_U(F.relu(self.conv2_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv4_t(x))\n",
    "        #merge4 = torch.cat((x,conv1_d),1)\n",
    "        x = F.relu(self.conv1_1_U(x))\n",
    "        x = self.bn_1_U(F.relu(self.conv1_2_U(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #classification layer\n",
    "        class_output = self.conv_sm(x)\n",
    "        #print(class_output.shape)\n",
    "        \n",
    "        #x_f output of feature extractio\n",
    "        x_f = conv5_d.view(-1,1024*8*8)\n",
    "        reverse_feature = ReverseLayerF.apply(x_f,alpha) # do not apply the reversed gradient\n",
    "        domain_output = self.discriminator(reverse_feature)\n",
    "        #domain_output = self.discriminator(x_f)\n",
    "        return class_output, domain_output\n",
    "\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
    "        super(UNET,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        #self.bn_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2= nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 1024, kernel_size=3, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(1024, 1024, kernel_size=3, padding = 1)\n",
    "        self.bn_5 = nn.BatchNorm2d(1024)\n",
    "    \n",
    "        #conv transpose layers\n",
    "        self.conv1_t = nn.ConvTranspose2d(1024, 512, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv2_t = nn.ConvTranspose2d(512, 256, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv3_t = nn.ConvTranspose2d(256, 128, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv4_t = nn.ConvTranspose2d(128, 64, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        \n",
    "        #upsampling layers\n",
    "        \n",
    "        self.conv4_1_U = nn.Conv2d(1024, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2_U = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4_U = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1_U = nn.Conv2d(512, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2_U = nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3_U = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2_1_U = nn.Conv2d(256, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2_U = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2_U = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv1_1_U = nn.Conv2d(128, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2_U = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1_U = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # final output layer\n",
    "        #self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=1, padding = 0)\n",
    "        self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "        # discriminator\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(1024*8*8, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x,alpha):\n",
    "        conv1_d = F.relu(self.conv1_1(x))\n",
    "        conv1_d = self.bn_1(F.relu(self.conv1_2(conv1_d)))\n",
    "        x = self.pool(conv1_d)\n",
    "        #conv1_d = self.pool()\n",
    "        \n",
    "        conv2_d = F.relu(self.conv2_1(x))\n",
    "        conv2_d = self.bn_2(F.relu(self.conv2_2(conv2_d)))\n",
    "        x = self.pool(conv2_d)\n",
    "        \n",
    "        conv3_d = F.relu(self.conv3_1(x))\n",
    "        conv3_d = self.bn_3(F.relu(self.conv3_2(conv3_d)))\n",
    "        x = self.pool(conv3_d)\n",
    "        \n",
    "        conv4_d = F.relu(self.conv4_1(x))\n",
    "        conv4_d = self.bn_4(F.relu(self.conv4_2(conv4_d)))\n",
    "        x = self.pool(conv4_d)\n",
    "        \n",
    "        conv5_d = F.relu(self.conv5_1(x))\n",
    "        conv5_d = self.bn_5(F.relu(self.conv5_2(conv5_d)))\n",
    "        \n",
    "        # x is the output to the domain and scene classfier\n",
    "        \n",
    "        x = F.relu(self.conv1_t(conv5_d))\n",
    "        merge1 = torch.cat((x,conv4_d),1)\n",
    "        x = F.relu(self.conv4_1_U(merge1))\n",
    "        x = self.bn_4_U(F.relu(self.conv4_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv2_t(x))\n",
    "        merge2 = torch.cat((x,conv3_d),1)\n",
    "        x = F.relu(self.conv3_1_U(merge2))\n",
    "        x = self.bn_3_U(F.relu(self.conv3_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3_t(x))\n",
    "        merge3 = torch.cat((x,conv2_d),1)\n",
    "        x = F.relu(self.conv2_1_U(merge3))\n",
    "        x = self.bn_2_U(F.relu(self.conv2_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv4_t(x))\n",
    "        merge4 = torch.cat((x,conv1_d),1)\n",
    "        x = F.relu(self.conv1_1_U(merge4))\n",
    "        x = self.bn_1_U(F.relu(self.conv1_2_U(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #classification layer\n",
    "        class_output = self.conv_sm(x)\n",
    "        #print(class_output.shape)\n",
    "        \n",
    "        #x_f output of feature extractio\n",
    "        x_f = conv5_d.view(-1,1024*8*8)\n",
    "        reverse_feature = ReverseLayerF.apply(x_f,alpha) # do not apply the reversed gradient\n",
    "        domain_output = self.discriminator(reverse_feature)\n",
    "        #domain_output = self.discriminator(x_f)\n",
    "        return class_output, domain_output\n",
    "\n",
    "def DeepCoral(source, target):\n",
    "    d = source.data.shape[1]\n",
    "    xm = torch.mean(source, 1, keepdim=True)\n",
    "    xc = torch.matmul(torch.transpose(xm, 0, 1), xm)  # source covariance\n",
    "    xmt = torch.mean(target, 1, keepdim=True)\n",
    "    xct = torch.matmul(torch.transpose(xmt, 0, 1), xmt)   # target covariance\n",
    "    loss = torch.mean(torch.mul((xc - xct), (xc - xct)))   # frobenius norm between source and target\n",
    "    return loss/(4*d*d)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
    "        super(UNET,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        #self.bn_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2= nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 1024, kernel_size=3, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(1024, 1024, kernel_size=3, padding = 1)\n",
    "        self.bn_5 = nn.BatchNorm2d(1024)\n",
    "    \n",
    "        #conv transpose layers\n",
    "        self.conv1_t = nn.ConvTranspose2d(1024, 512, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv2_t = nn.ConvTranspose2d(512, 256, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv3_t = nn.ConvTranspose2d(256, 128, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        self.conv4_t = nn.ConvTranspose2d(128, 64, stride=2, kernel_size=3, padding = 1,output_padding =1)\n",
    "        \n",
    "        #upsampling layers\n",
    "        \n",
    "        self.conv4_1_U = nn.Conv2d(1024, 512, kernel_size=3, padding = 1)\n",
    "        self.conv4_2_U = nn.Conv2d(512, 512, kernel_size=3, padding = 1)\n",
    "        self.bn_4_U = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1_U = nn.Conv2d(512, 256, kernel_size=3, padding = 1)\n",
    "        self.conv3_2_U = nn.Conv2d(256, 256, kernel_size=3, padding = 1)\n",
    "        self.bn_3_U = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2_1_U = nn.Conv2d(256, 128, kernel_size=3, padding = 1)\n",
    "        self.conv2_2_U = nn.Conv2d(128, 128, kernel_size=3, padding = 1)\n",
    "        self.bn_2_U = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv1_1_U = nn.Conv2d(128, 64, kernel_size=3, padding = 1)\n",
    "        self.conv1_2_U = nn.Conv2d(64, 64, kernel_size=3, padding = 1)\n",
    "        self.bn_1_U = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # final output layer\n",
    "        #self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=1, padding = 0)\n",
    "        self.conv_sm = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "        # discriminator\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(1024*8*8, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv1_d = F.relu(self.conv1_1(x))\n",
    "        conv1_d = self.bn_1(F.relu(self.conv1_2(conv1_d)))\n",
    "        x = self.pool(conv1_d)\n",
    "        #conv1_d = self.pool()\n",
    "        \n",
    "        conv2_d = F.relu(self.conv2_1(x))\n",
    "        conv2_d = self.bn_2(F.relu(self.conv2_2(conv2_d)))\n",
    "        x = self.pool(conv2_d)\n",
    "        \n",
    "        conv3_d = F.relu(self.conv3_1(x))\n",
    "        conv3_d = self.bn_3(F.relu(self.conv3_2(conv3_d)))\n",
    "        x = self.pool(conv3_d)\n",
    "        \n",
    "        conv4_d = F.relu(self.conv4_1(x))\n",
    "        conv4_d = self.bn_4(F.relu(self.conv4_2(conv4_d)))\n",
    "        x = self.pool(conv4_d)\n",
    "        \n",
    "        conv5_d = F.relu(self.conv5_1(x))\n",
    "        conv5_d = self.bn_5(F.relu(self.conv5_2(conv5_d)))\n",
    "        \n",
    "        # x is the output to the domain and scene classfier\n",
    "        \n",
    "        x = F.relu(self.conv1_t(conv5_d))\n",
    "        merge1 = torch.cat((x,conv4_d),1)\n",
    "        x = F.relu(self.conv4_1_U(merge1))\n",
    "        x = self.bn_4_U(F.relu(self.conv4_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv2_t(x))\n",
    "        merge2 = torch.cat((x,conv3_d),1)\n",
    "        x = F.relu(self.conv3_1_U(merge2))\n",
    "        x = self.bn_3_U(F.relu(self.conv3_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3_t(x))\n",
    "        merge3 = torch.cat((x,conv2_d),1)\n",
    "        x = F.relu(self.conv2_1_U(merge3))\n",
    "        x = self.bn_2_U(F.relu(self.conv2_2_U(x)))\n",
    "        \n",
    "        x = F.relu(self.conv4_t(x))\n",
    "        merge4 = torch.cat((x,conv1_d),1)\n",
    "        x = F.relu(self.conv1_1_U(merge4))\n",
    "        x = self.bn_1_U(F.relu(self.conv1_2_U(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #classification layer\n",
    "        class_output = self.conv_sm(x)\n",
    "        #print(class_output.shape)\n",
    "        \n",
    "        #x_f output of feature extractio\n",
    "        bottleneck_feature = conv5_d.view(-1,1024*8*8)\n",
    "        #reverse_feature = ReverseLayerF.apply(x_f,alpha) # do not apply the reversed gradient\n",
    "        #domain_output = self.discriminator(reverse_feature)\n",
    "        #domain_output = self.discriminator(x_f)\n",
    "        #return class_output, domain_output\n",
    "        return class_output,bottleneck_feature\n",
    "\n",
    "#sgm = torch.nn.Sigmoid()\n",
    "#x = sgm(self.conv_sm(x))\n",
    "#criterion_1 = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "#weights = [5.55,2.26,2.01,1,1.8,2.0]\n",
    "#weights = [3.0,2.26,2.01,1,1.8,2.0]\n",
    "#weights = [11,4,1,1,1,1]\n",
    "weights = [1,1,1,1,1,1]\n",
    "\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "#self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "##define training schedule for da\n",
    "\n",
    "def train(net, optimizer, epochs, src_data_loader,tgt_data_loader,device,scheduler=None, weights=None, save_epoch = 5):\n",
    "    #weights = weights.cuda() # weights for class balancing\n",
    "    #criterion = nn.NLLLoss(weight = weights)\n",
    "    #criterion_1 = torch.nn.BCEWithLogitsLoss() #discriminator\n",
    "    criterion_1 = nn.CrossEntropyLoss() #discriminator\n",
    "    \n",
    "    criterion_2 = nn.CrossEntropyLoss(weight = None,ignore_index=-1) #classifier\n",
    "    val_loss_history = []\n",
    "    \n",
    "    src_cl_loss_history = []\n",
    "    #src_dl_loss_history = []\n",
    "    #tgt_dl_loss_history = []\n",
    "    tra_acc_history = []\n",
    "    coral_loss_history = []\n",
    "    #dom_acc_history=[]\n",
    "    m=[]\n",
    "    \n",
    "    iter_ = 0\n",
    "    best_acc =0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"epoch number %d\"%epoch)\n",
    "        print('-'*10)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        net.train()\n",
    "        \n",
    "        len_dataloader = min(len(src_data_loader), len(tgt_data_loader))\n",
    "        data_zip = enumerate(zip(src_data_loader,tgt_data_loader))\n",
    "        running_loss = 0.0\n",
    "        run_src_cl = 0.0\n",
    "        run_src_dl = 0.0\n",
    "        #run_tgt_dl = 0.0\n",
    "        run_acc = 0.0\n",
    "        d_acc = 0.0\n",
    "        run_coral = 0.0\n",
    "        \n",
    "        dom_preds = []\n",
    "        \n",
    "        for batch_idx, ((images_src,class_src),(images_tgt,_)) in data_zip:\n",
    "            p = float(batch_idx + epoch * len_dataloader) /\\\n",
    "            epochs / len_dataloader\n",
    "            #alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "            #alpha =1\n",
    "            #depreciate the lr\n",
    "            #lr = 0.01 / (1. + 10 * p)**0.75\n",
    "            #optimizer.lr = lr\n",
    "            \n",
    "            size_src = len(images_src)\n",
    "            size_tgt = len(images_tgt)\n",
    "            #label_src = torch.zeros(size_src,1).long().to(device) # source 0 #change to long for CEL\n",
    "            #label_tgt = torch.ones(size_tgt,1).long().to(device) # target 1\n",
    "            \n",
    "            # for CEL no need ofr extra dim\n",
    "            label_src = torch.zeros(size_src).long().to(device) # source 0 #change to long for CEL\n",
    "            label_tgt = torch.ones(size_tgt).long().to(device) # target 1\n",
    "            \n",
    "            #labels = torch.cat((torch.zeros(size_src,1).float(),torch.ones(size_tgt,1).float()),0).to(device)\n",
    "            \n",
    "            #make images variable\n",
    "            class_src = class_src.squeeze(1).to(device) #cross entropy\n",
    "            #class_src = class_src.to(device)\n",
    "            \n",
    "            images_src = images_src.to(device)\n",
    "            images_tgt = images_tgt.to(device)\n",
    "            #images = torch.cat((images_src,images_tgt),0).to(device)\n",
    "            \n",
    "            #print(torch.max(class_src),torch.min(class_src))\n",
    "        \n",
    "            #data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "            #zero grad for the optimizer\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #train on the images\n",
    "            #images = torch.cat((images_src,images_tgt),0).to(device)\n",
    "            #class_output, domain_output = net(x=images, alpha = alpha)\n",
    "            #img_loss = criterion_1(domain_output,labels)\n",
    "\n",
    "            #train on source domain\n",
    "            src_class_output, src_domain_output = net(x=images_src.float().to(device))\n",
    "            src_loss_class = criterion_2(src_class_output,class_src.long())\n",
    "            #print(label_src)\n",
    "            #print(src_domain_output)\n",
    "            \n",
    "            \n",
    "            #src_loss_domain = criterion_1(src_domain_output, label_src)\n",
    "            \n",
    "            #train on target domain\n",
    "            _, tgt_domain_output =net(x=images_tgt.float())\n",
    "            #tgt_loss_domain = criterion_1(tgt_domain_output, label_tgt)\n",
    "            \n",
    "            # COMPUTE THE  CORAL LOSS\n",
    "            \n",
    "            lamb_da = epoch/epochs\n",
    "            \n",
    "            coral_loss = DeepCoral(src_domain_output,tgt_domain_output)\n",
    "            #loss = src_loss_class + lamb_da*coral_loss\n",
    "\n",
    "            loss = src_loss_class\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #pred the domain class\n",
    "            #tsm = torch.nn.Sigmoid()\n",
    "            #src_dom_class = tsm(src_domain_output)\n",
    "            #src_dom_class = src_dom_class.data.cpu().numpy()\n",
    "            #domain accuracy\n",
    "            #dom_pred = torch.argmax(src_domain_output,1)\n",
    "            #dom_acc = (dom_pred == label_src).float().mean()\n",
    "            #print(dom_acc)\n",
    "            #d_acc+=dom_acc.item()*images_src.size(0)\n",
    "            \n",
    "            \n",
    "            #get the mean\n",
    "            #dom_src_lab = torch.zeros(size_src,1).to(device)\n",
    "            #s = (src_dom_class<0.5)\n",
    "            #d = (dom_src_lab==0)\n",
    "            #t = (s==d).float().mean()\n",
    "            #print(d)\n",
    "            #dom_preds.append(src_dom_class)\n",
    "            #print('src_dom class',src_dom_class)\n",
    "\n",
    "            #print(src_dom_class)\n",
    "            \n",
    "            pred = torch.argmax(src_class_output, 1)\n",
    "            acc = (pred == class_src).float().mean()\n",
    "            #print(acc)\n",
    "            run_acc+=acc.item()*images_src.size(0)\n",
    "            \n",
    "            #saving the loss\n",
    "            running_loss +=loss.item()*images_src.size(0)\n",
    "            #running_loss +=loss.item()*images.size(0)\n",
    "            \n",
    "            #the individual losses\n",
    "            run_src_cl += src_loss_class.item()*images_src.size(0)\n",
    "            run_coral += coral_loss.item()*images_src.size(0)\n",
    "            #run_src_dl += src_loss_domain.item()*images_src.size(0)\n",
    "            #run_tgt_dl += tgt_loss_domain.item()*images_src.size(0)\n",
    "            #print(images_src.size(0))\n",
    "            \n",
    "            iter_+=1\n",
    "        \n",
    "        epoch_loss = running_loss/ (len(src_data_loader.dataset)+len(src_data_loader.dataset))\n",
    "        val_loss_history.append(epoch_loss)\n",
    "        \n",
    "        tra_acc_history.append(run_acc/len(src_data_loader.dataset))\n",
    "        #dom_acc_history.append(d_acc/len(src_data_loader.dataset))\n",
    "       \n",
    "        #save the individual losses to a list\n",
    "        epoch_loss = run_src_cl/ len(src_data_loader.dataset)\n",
    "        src_cl_loss_history.append(epoch_loss)\n",
    "        \n",
    "        # coral loss\n",
    "        \n",
    "        epoch_loss = run_coral/ len(src_data_loader.dataset)\n",
    "        coral_loss_history.append(epoch_loss)\n",
    "        \n",
    "        \n",
    "        #epoch_loss = run_src_dl/ len(src_data_loader.dataset)\n",
    "        #src_dl_loss_history.append(epoch_loss)\n",
    "        \n",
    "        #epoch_loss = run_tgt_dl/ len(src_data_loader.dataset)\n",
    "        #tgt_dl_loss_history.append(epoch_loss)\n",
    "        #print(len(src_data_loader.dataset))\n",
    "        \n",
    "        #saving a checkpoint\n",
    "        #acc1 = run_acc/len(src_data_loader.dataset)\n",
    "        #is_best = acc1>best_acc\n",
    "        #best_acc = max(acc1,best_acc)\n",
    "        #print(best_acc)\n",
    "        #if is_best:\n",
    "            #torch.save(net.state_dict(), output_dir+str(epoch)+\"_buj_100.hdf5\")\n",
    "            #torch.save(net.state_dict(), w8_fname)\n",
    "            #print(\"saved epoch\",epoch)\n",
    "    torch.save(net.state_dict(), w8_fname)\n",
    "    #return val_loss_history,tra_acc_history,dom_acc_history,src_cl_loss_history,src_dl_loss_history,tgt_dl_loss_history\n",
    "    return val_loss_history, tra_acc_history, coral_loss_history, src_cl_loss_history\n",
    "\n",
    "##########\n",
    "#FUNCTIONS FOR TESTING STAGE\n",
    "##########\n",
    "\n",
    "#testing for one class\n",
    "## functions for testing \n",
    "import itertools\n",
    "import subprocess, glob\n",
    "from random import seed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "seed(1234)\n",
    "\n",
    "\n",
    "BATCH_SIZE=8\n",
    "WINDOW_SIZE=[256,256]\n",
    "patch_size=256\n",
    "STRIDE=228\n",
    "nc=6\n",
    "gmax=63450\n",
    "#gmax=45000\n",
    "gmin=0\n",
    "\n",
    "# CREATE DIRECTORIES\n",
    "def make_dir_paths(mypath):\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "        print(\"created path\")\n",
    "\n",
    "## REMOVE NULLS\n",
    "def nulltozero(arr):\n",
    "    arrcopy = np.copy(arr)\n",
    "    low_values_flags = arrcopy < 0 #0.7,0  \n",
    "    arrcopy[low_values_flags]=0\n",
    "    return arrcopy\n",
    "\n",
    "#LOAD IMAGES AND CONVERT TO ARRAYS\n",
    "def img_to_array(*images):\n",
    "    \"\"\"Convert an image or list of images to numpy arrays.\n",
    "\n",
    "    Keyword arguments:\n",
    "    *images -- list containing the images to be converted\n",
    "    \"\"\"\n",
    "    imgarrays = []\n",
    "    i = 0\n",
    "    for img in images:\n",
    "        arr = gtiff_to_array(img)\n",
    "        imgarrays.append(arr)\n",
    "    return imgarrays\n",
    "\n",
    "\n",
    "def gtiff_to_array(imgfname):                                      \n",
    "    \"\"\"Transform a geotiff to numpy array.\n",
    "\n",
    "    Keyword arguments:\n",
    "    imgfnames -- filename of image to convert\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(imgfname)\n",
    "    for band in range(ds.RasterCount):\n",
    "        band += 1\n",
    "        if band == 1:\n",
    "            arr = np.array(ds.GetRasterBand(band).ReadAsArray())\n",
    "            arr = np.expand_dims(arr, axis=2)\n",
    "        else:\n",
    "            concat = np.array(ds.GetRasterBand(band).ReadAsArray())\n",
    "            concat = np.expand_dims(concat, axis=2)\n",
    "            arr = np.concatenate((arr,\n",
    "                                  concat),\n",
    "                                 axis=2)\n",
    "    return arr\n",
    "\n",
    "def reclassgts2(gtsarray):\n",
    "    \"\"\"Reclassify ground truth dataset array to single class numbers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    gtsarray -- the ground truth dataset array\n",
    "    \"\"\"\n",
    "    reclassarray = np.zeros(shape=(gtsarray.shape[0], gtsarray.shape[1]),\n",
    "                            dtype=np.uint8)\n",
    "    cnum = 1\n",
    "    mask = np.logical_or(np.logical_or(gtsarray[:,:,0]==1,gtsarray[:,:,0]==3),gtsarray[:,:,0]==4)\n",
    "    reclassarray[mask]=cnum\n",
    "\n",
    "    cnum2 = 2\n",
    "    mask = np.logical_or(gtsarray[:,:,0]==2,gtsarray[:,:,0]==2)\n",
    "    reclassarray[mask] = cnum2\n",
    "    return reclassarray\n",
    "\n",
    "#create idxarray for the creation of the map\n",
    "def sample_idx(arr):\n",
    "    \"\"\"Randomly sample an array stratified based on frequency.\n",
    "\n",
    "    Keyword arguments:\n",
    "    arr -- the array being sampled\n",
    "    cratios -- the representative fractions of each classes\n",
    "    n -- total number of samples (default 1000)\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    arr_copy = np.copy(arr)\n",
    "    idxarray = np.zeros(shape=(0, 2), dtype=np.int16)\n",
    "    nc = np.array(np.where(arr_copy >0)).T.shape[0]\n",
    "    arr_flat = arr_copy.flatten()\n",
    "    n = arr_flat.shape[0]\n",
    "    randidx = np.asarray(range(n),dtype= np.int32)\n",
    "    #randidx=randidx.astype(np.int32)\n",
    "    idxarray = np.array(np.where(arr_copy >= 0)).T[randidx, :]\n",
    "    #sampleidx += csamples\n",
    "\n",
    "    del arr_copy\n",
    "    return idxarray\n",
    "\n",
    "def write_geotiff(fname, data, geo_transform, projection):\n",
    "    \"\"\"Create a GeoTIFF file with the given data.\"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    dataset = None  # Close the file\n",
    "\n",
    "def swap_axes(arr):\n",
    "    return np.expand_dims(arr, axis = 0)\n",
    "\n",
    "#REMOVE NAN\n",
    "def nulltozero_g(arr):\n",
    "    arrcopy = np.copy(arr)\n",
    "    low_values_flags = (np.isnan(arr))#0.7,0\n",
    "    arrcopy[low_values_flags]=0\n",
    "    return arrcopy\n",
    "\n",
    "def extract_geometry(path_dir):\n",
    "    raster_dataset = gdal.Open(path_dir, gdal.GA_ReadOnly)\n",
    "    geo_transform = raster_dataset.GetGeoTransform()\n",
    "\n",
    "    return geo_transform\n",
    "\n",
    "# Utils adapting the prediction scheme in https://github.com/nshaud/DeepNetsForEO/blob/master/SegNet_PyTorch_v2.ipynb\n",
    "#https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "\n",
    "\n",
    "def get_random_pos(img, window_shape):\n",
    "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
    "    w, h = window_shape\n",
    "    W, H = img.shape[-2:]\n",
    "    x1 = random.randint(0, W - w - 1)\n",
    "    x2 = x1 + w\n",
    "    y1 = random.randint(0, H - h - 1)\n",
    "    y2 = y1 + h\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "def accuracy(input, target):\n",
    "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
    "\n",
    "def sliding_window(top, step=10, window_size=(32,32)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "\n",
    "def count_sliding_window(top, step=10, window_size=(32,32)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "def swap_a(ar):\n",
    "    ar1 = np.swapaxes(ar,1,3)\n",
    "    ar2 = np.swapaxes(ar1,2,3)\n",
    "    return ar2\n",
    "def test(net, img_arr,N_CLASSES,stride=WINDOW_SIZE[0], batch_size=BATCH_SIZE, window_size=WINDOW_SIZE):\n",
    "    \n",
    "    # Use the network on the test set\n",
    "    all_preds = []\n",
    "    all_probs=[]\n",
    "    all_gts = []\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    net.to(torch.double)\n",
    "    with torch.no_grad():\n",
    "        for img in img_arr:\n",
    "            #print (img.shape)\n",
    "            pred = np.zeros(img.shape[:2] + (N_CLASSES,))\n",
    "            prob = np.zeros(img.shape[:2] + (N_CLASSES,))\n",
    "            for i, coords in enumerate(grouper(batch_size, sliding_window(img, step=stride, window_size=window_size))):\n",
    "                image_patches_1=[]\n",
    "                image_patches = [np.copy(np.expand_dims(img[x:x+w, y:y+h],axis=0)) for x,y,w,h in coords]\n",
    "                image_patches_1= np.concatenate(image_patches, axis=0)\n",
    "                #print()\n",
    "                \n",
    "                #swap axes\n",
    "                image_patches_1= swap_a(image_patches_1)\n",
    "                print(\"images_patches_1.shape\",image_patches_1.shape)\n",
    "\n",
    "                image_patches_1 = Variable(torch.from_numpy(image_patches_1).cuda())\n",
    "                # Do the inference\n",
    "                #outs = net.classifier(net.feature(image_patches_1))\n",
    "                outs,dom_out = net(x=image_patches_1)\n",
    "                #sgm = torch.nn.Sigmoid()\n",
    "                #outs = sgm(outs)\n",
    "                del image_patches # clear mem\n",
    "\n",
    "                outs = outs.data.cpu().numpy()\n",
    "                print(outs.shape)\n",
    "                # Fill in the results array\n",
    "                for out, (x, y, w, h) in zip(outs, coords):\n",
    "                    out = out.transpose((1,2,0))\n",
    "                    #pred[x:x+w, y:y+h] += out  #this creates addition in the overlap regions\n",
    "                    print(\"out shape\",out.shape)\n",
    "\n",
    "                    pred[x:x+w, y:y+h] = out\n",
    "                del(outs)\n",
    "            \"use the np max for max probability\"\n",
    "            #prob = np.max(pred, axis=2)\n",
    "            pred = np.argmax(pred, axis=2)\n",
    "            #print(\"pred shape\",pred.shape)\n",
    "\n",
    "            all_preds.append(pred)\n",
    "            all_probs.append(prob)\n",
    "\n",
    "    return all_preds,all_probs\n",
    "\n",
    "#Reclassifying the array and giving it coordinates\n",
    "def reclass_gts(gtsarray):\n",
    "    \"\"\"Reclassify ground truth dataset array to single class numbers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    gtsarray -- the ground truth dataset array\n",
    "    \"\"\"\n",
    "    reclassarray = np.zeros(shape=(gtsarray.shape[0], gtsarray.shape[1]),\n",
    "                            dtype=np.uint8)\n",
    "    cnum = 1\n",
    "    for color in _ccolors:\n",
    "        mask = np.logical_and(np.logical_and(gtsarray[:, :, 0] == color[0],\n",
    "                              gtsarray[:, :, 1] == color[1]),\n",
    "                              gtsarray[:, :, 2] == color[2])\n",
    "        reclassarray[mask] = cnum\n",
    "        cnum += 1\n",
    "    return reclassarray\n",
    "\n",
    "def save_to_1band(arr,out_path,geom,proj):\n",
    "    #save a one band image\n",
    "    #p_rec is the reclassified array and has two dimensions\n",
    "    #pred_map_GCs2 = predsdir + \"trainingset_3/georeferenced/fcn_atr_goma_1947_clip1_1bands.tif\"\n",
    "    arr=np.expand_dims(arr, axis=2)\n",
    "    nrows,ncols,nbands = arr.shape[0],arr.shape[1],arr.shape[2]\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    nw_ds = driver.Create(out_path, ncols, nrows, nbands, gdal.GDT_UInt32 )\n",
    "    nw_ds.SetGeoTransform(geom)\n",
    "    nw_ds.SetProjection(proj)\n",
    "\n",
    "    nw_ds.GetRasterBand(1).WriteArray(arr[:, :,0])\n",
    "\n",
    "    #for i in range(nbands):\n",
    "    #\tnw_ds.GetRasterBand(i+1).WriteArray(P_rec[:, :, i])\n",
    "\n",
    "    nw_ds = None\n",
    "\n",
    "def save_prob_1band(arr,out_path,geom,proj):\n",
    "    #save a one band image\n",
    "    #p_rec is the reclassified array and has two dimensions\n",
    "    #pred_map_GCs2 = predsdir + \"trainingset_3/georeferenced/fcn_atr_goma_1947_clip1_1bands.tif\"\n",
    "    arr=np.expand_dims(arr, axis=2)\n",
    "    nrows,ncols,nbands = arr.shape[0],arr.shape[1],arr.shape[2]\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    nw_ds = driver.Create(out_path, ncols, nrows, nbands, gdal.GDT_Float32 )\n",
    "    nw_ds.SetGeoTransform(geom)\n",
    "    nw_ds.SetProjection(proj)\n",
    "\n",
    "    nw_ds.GetRasterBand(1).WriteArray(arr[:, :,0])\n",
    "\n",
    "    #for i in range(nbands):\n",
    "    #\tnw_ds.GetRasterBand(i+1).WriteArray(P_rec[:, :, i])\n",
    "\n",
    "    nw_ds = None\n",
    "\n",
    "# normalize the top array\n",
    "def norm_rgbn(data,gmax,gmin):\n",
    "    \"\"\"\n",
    "    rexcale  the multispectral data [0,1]\n",
    "    data--the multispectral array\n",
    "    \"\"\"\n",
    "    data = data.astype(float)\n",
    "    data_norm = (data - gmin)/(gmax - gmin)\n",
    "    return data_norm\n",
    "\n",
    "def data_proj(arr_path):\n",
    "    raster_dataset = gdal.Open(arr_path, gdal.GA_ReadOnly)\n",
    "    geo_transform = raster_dataset.GetGeoTransform()\n",
    "    proj = raster_dataset.GetProjectionRef()\n",
    "    return geo_transform,proj\n",
    "\n",
    "\n",
    "# ACCURACY METRICS FUNCTIONS \n",
    "def create_mask_from_vector(vector_data_path, cols, rows, geo_transform,\n",
    "                            projection, target_value=1):\n",
    "    \"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\"\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    #gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[target_value])\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, options =[\"ATTRIBUTE=class_id\"])    \n",
    "    return target_ds\n",
    "    #gdal.RasterizeLayer()\n",
    "\n",
    "def vectors_to_raster(path, rows, cols, geo_transform, projection):\n",
    "    \"\"\"Rasterize the vectors in the given directory in a single image.\"\"\"\n",
    "    labeled_pixels = np.zeros((rows, cols))\n",
    "    label = 1\n",
    "    ds = create_mask_from_vector(path, cols, rows, geo_transform,\n",
    "                                 projection, target_value=label)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    labeled_pixels += band.ReadAsArray()\n",
    "    ds = None\n",
    "    return labeled_pixels\n",
    "\n",
    "def write_geotiff(fname, data, geo_transform, projection):\n",
    "    \"\"\"Create a GeoTIFF file with the given data.\"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    dataset = None  # Close the file\n",
    "    \n",
    "# convert the geotiff to a numpy array\n",
    "\n",
    "def gtiff_to_array(imgfname):\n",
    "    \"\"\"Transform a geotiff to numpy array.\n",
    "\n",
    "    Keyword arguments:\n",
    "    imgfnames -- filename of image to convert\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(imgfname)\n",
    "    for band in range(ds.RasterCount):\n",
    "        band += 1\n",
    "        if band == 1:\n",
    "            arr = np.array(ds.GetRasterBand(band).ReadAsArray())\n",
    "            arr = np.expand_dims(arr, axis=2)\n",
    "        else:\n",
    "            concat = np.array(ds.GetRasterBand(band).ReadAsArray())\n",
    "            concat = np.expand_dims(concat, axis=2)\n",
    "            arr = np.concatenate((arr,\n",
    "                                  concat),\n",
    "                                 axis=2)\n",
    "    return arr\n",
    "\n",
    "def img_to_array(*images):\n",
    "    \"\"\"Convert an image or list of images to numpy arrays.\n",
    "\n",
    "    Keyword arguments:\n",
    "    *images -- list containing the images to be converted\n",
    "    \"\"\"\n",
    "    imgarrays = []\n",
    "    i = 0\n",
    "    for img in images:\n",
    "        arr = gtiff_to_array(img)\n",
    "        imgarrays.append(arr)\n",
    "    return imgarrays\n",
    "\n",
    "# sampling an array\n",
    "def sample_idx(arr):\n",
    "    \"\"\"Randomly sample an array\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    arr_copy = np.copy(arr)\n",
    "    idxarray = np.zeros(shape=(0, 2), dtype=np.int16)\n",
    "    nc = np.array(np.where(arr_copy >0)).T.shape[0]\n",
    "    #find how to automatically select the samples\n",
    "    randidx = np.random.choice(range(nc),\n",
    "                               size=nc, replace=False)\n",
    "    randidx=randidx.astype(np.int32)\n",
    "    idxarray = np.array(np.where(arr_copy > 0)).T[randidx, :]\n",
    "\n",
    "    del arr_copy\n",
    "    return idxarray\n",
    "\n",
    "def extract_values(f,idx):\n",
    "    #extract values from an array \n",
    "    samples=[]\n",
    "    samples.append(np.asarray([f[rc[0],rc[1], ]\n",
    "                                          for rc in idx]))\n",
    "    samples_arr=np.concatenate(samples, axis=0)\n",
    "    return samples_arr\n",
    "    \n",
    "\n",
    "def sample_idx_freq(arr,cratios,n):\n",
    "    \"\"\"Randomly stratified array sampling\n",
    "    \"\"\"\n",
    "    arr_copy = np.copy(arr)\n",
    "    idxarray = np.zeros(shape=(0, 2), dtype = np.int16)\n",
    "    nclasses = len(cratios)\n",
    "\n",
    "    for i in range (nclasses):\n",
    "        csamples = int(round(n*cratios[i]))\n",
    "        nc = np.array(np.where(arr_copy==i+1)).T.shape[0]\n",
    "        print(nc)\n",
    "        if nc>0:\n",
    "            randidx = np.random.choice(range(nc),\n",
    "                               size = csamples, replace = True)\n",
    "            idxarray = np.concatenate((idxarray,\n",
    "                                   np.array(np.where(arr_copy == i+1)).T\n",
    "                                   [randidx, :]),\n",
    "                                  axis=0)\n",
    "    del arr_copy\n",
    "    return idxarray\n",
    "#use a fixed test set\n",
    "def extract_values(f,idx):\n",
    "    #extract values from an array \n",
    "    samples=[]\n",
    "    samples.append(np.asarray([f[rc[0],rc[1], ]\n",
    "                                          for rc in idx]))\n",
    "    samples_arr=np.concatenate(samples, axis=0)\n",
    "    return samples_arr\n",
    "\n",
    "def make_dir_paths(mypath):\n",
    "    if not os.path.isdir(mypath):\n",
    "        os.makedirs(mypath)\n",
    "        print(\"created path\")\n",
    "        \n",
    "def reclass_preds(arr, value, reclass_value):\n",
    "    \n",
    "    arr_copy=np.copy(arr)\n",
    "    \n",
    "    for i in range(len(arr_copy)):\n",
    "        if arr_copy[i]>value:\n",
    "            arr_copy[i]=reclass_value\n",
    "    \n",
    "    return arr_copy\n",
    "\n",
    "\n",
    "#SLICE_1 = [100,200,400,800,1600,2000]\n",
    "#SLICE_2 = [25,50,100,200,400,500]\n",
    "#SLICE_1 = [400]\n",
    "#SLICE_2 = [100]\n",
    "#SLICE_1 = [100,200,400]\n",
    "#SLICE_2 = [25,50,100]\n",
    "#SLICE_1 = [100,200,300]\n",
    "#SLICE_2 = [25,50,75]\n",
    "#SLICE_1 = [50,400,800]\n",
    "#SLICE_2 = [25,50,100]\n",
    "\n",
    "SLICE_3 = [300,450,600] # numbr of samples to draw\n",
    "seed_value = [10,100,500,1000,10000]\n",
    "\n",
    "\n",
    "src_data_dir ='H:/DA_ETH/DRC_BALANCED/buk_59.hdf5'\n",
    "tgt_data_dir ='H:/DA_ETH/DRC_BALANCED/gom_47.hdf5'\n",
    "\n",
    "for j in seed_value:\n",
    "    \n",
    "    for i in range(len(SLICE_1)):\n",
    "        #JOB_ID = str(SLICE_1[i]+2*SLICE_2[i])\n",
    "        JOB_ID = str(SLICE_3[i])+\"_\"+str(j)\n",
    "        w8_fname = 'H:/DA_ETH/DRC_BALANCED/WEIGHTS/'+JOB_ID+'_FT_CORAL_gom_src_150_stat_pp4.hdf5'\n",
    "        model = UNET().to(device)\n",
    "\n",
    "        w8_ft_fname = \"H:/DA_ETH/DRC_BALANCED/WEIGHTS/150_CORAL_goma_src.hdf5\"\n",
    "        model.load_state_dict(torch.load(w8_ft_fname))\n",
    "\n",
    "        base_lr = 0.001\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0005)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "        src_dataset = MyDataset_BK(src_data_dir,slice_3=SLICE_3[i],seed_value = j)\n",
    "        tgt_dataset = MyDataset_GM(tgt_data_dir,slice_3=SLICE_3[i],seed_value = j)\n",
    "        #using the data loader\n",
    "        src_dataloader = data.DataLoader(dataset = src_dataset, batch_size = 8, shuffle = True)\n",
    "        tgt_dataloader = data.DataLoader(dataset = tgt_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "        t0 = time.time()\n",
    "        loss_history = train(model,optimizer,50,src_dataloader,tgt_dataloader,device, scheduler=None)\n",
    "        t1 = time.time()\n",
    "\n",
    "        print(\"training complete in %0.2f\"%((t1-t0)/60))\n",
    "        #val_loss_history, tra_acc_history, coral_loss_history, src_cl_loss_history\n",
    "        # save the loss values\n",
    "        loss_folder = 'H:/DA_ETH/DRC_BALANCED/FIGURES/'+JOB_ID+'_FT_CORAL_loss_gom_src_150_stat_pp4.hdf5'\n",
    "        with h5.File(loss_folder,\"w\") as f:\n",
    "            f['loss_tot'] = loss_history[0]\n",
    "            f['tra_acc'] = loss_history[1]\n",
    "            f['dom_acc'] = loss_history[2]\n",
    "            f['src_cl_loss'] = loss_history[3]\n",
    "            #f['src_dl_loss'] = loss_history[4]\n",
    "            #f['tgt_dl_loss'] = loss_history[5]\n",
    "\n",
    "        # testing part fits in here\n",
    "\n",
    "        EXPT_ID = 'GM_S_CORAL_FT_150_stat_PP4_'+JOB_ID\n",
    "        root_path = \"H:/DRC_THESIS/DNN_LABELLED_DATA/buk_prel_test_25_11\"\n",
    "\n",
    "        raw_files_pan = glob.glob(root_path+'/raw_tif_totest/*.tif')\n",
    "        mini_preds_folder = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/predictions/MINI_TILES\"\n",
    "        probs_folder = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/probabilities/WHOLE_TILE_PROBS\"\n",
    "\n",
    "        make_dir_paths(probs_folder)\n",
    "        make_dir_paths(mini_preds_folder)\n",
    "\n",
    "\n",
    "        ## TEST MODEL\n",
    "        t0 = time.time()\n",
    "\n",
    "        dom_net= UNET()\n",
    "        dom_net.load_state_dict(torch.load(w8_fname))\n",
    "        #dom_net = dom_net.classifier\n",
    "\n",
    "        for rgbn in raw_files_pan[:]:\n",
    "            rgbn_raw=img_to_array(rgbn)\n",
    "            geo_info,projec_info=data_proj(rgbn)\n",
    "\n",
    "            #normalize the rgb\n",
    "            rgbn_norm=norm_rgbn(rgbn_raw[0],gmax,gmin)\n",
    "            del rgbn_raw\n",
    "            #rgbn_norm = swap_a(rgbn_norm)\n",
    "\n",
    "            allpred= test(dom_net,[rgbn_norm],nc,stride=STRIDE)\n",
    "\n",
    "            file_name=os.path.split(rgbn)[-1]\n",
    "            save_to_1band(allpred[0][0]+1,mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_prob_1band(allpred[0][0],mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_to_1band(allpred[0][0]+1,mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_prob_1band(allpred[1][0],probs_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(\"Finished testing after %.2f mins\" % ((t1-t0)/60.0))\n",
    "\n",
    "\n",
    "        #COMPUTE THE ACCURACY METRICS\n",
    "\n",
    "        txtcontent = \"\"\n",
    "\n",
    "        logs_folder=root_path+\"/RESULTS_METRICS_6CLASSES/\"+EXPT_ID+\"/FIGURES_TIME_LOGS\"\n",
    "        make_dir_paths(logs_folder)\n",
    "\n",
    "        class_path = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/predictions/MINI_TILES\"\n",
    "        #gts_files = glob.glob(root_path+\"/gts_tif_totest/*.tif\")\n",
    "        gts_files = glob.glob(root_path+\"/gts_tif2_test/*.tif\")\n",
    "        class_files= glob.glob(class_path+'/*.tif')\n",
    "\n",
    "        t0 = time.time()\n",
    "        num_tiles=len(gts_files)\n",
    "        counter = 0\n",
    "        all_gts=[]\n",
    "        all_labeled=[]\n",
    "\n",
    "        for gts,classified in zip(gts_files,class_files):\n",
    "            counter += 1\n",
    "            print(\"Tile %i of %i\" % (counter, num_tiles))\n",
    "            #importing the rasters\n",
    "            refs,labeled= img_to_array(gts,classified)\n",
    "\n",
    "            #reshape reference\n",
    "            refs = np.reshape (refs,(refs.shape[0],refs.shape[1]))\n",
    "            #reshape labels\n",
    "            labeled = np.reshape(labeled,(labeled.shape[0],labeled.shape[1]))\n",
    "\n",
    "            #idxarray = sample_idx_freq(refs,cratios,n) #\n",
    "            idxarray = sample_idx(refs) #\n",
    "\n",
    "            #extract the gts pixels into an array\n",
    "            idx_gts= extract_values(refs,idxarray)\n",
    "\n",
    "            #extract the pred pixels into an array\n",
    "            idx_pred=extract_values(labeled,idxarray)\n",
    "\n",
    "            #trainset=trainset[rand_list]\n",
    "            all_gts.append(idx_gts)\n",
    "            all_labeled.append(idx_pred)\n",
    "\n",
    "        #saving    \n",
    "        all_gts_arr=np.asarray(all_gts)\n",
    "        gts_set= np.concatenate(all_gts, axis=0)\n",
    "\n",
    "        all_preds_arr=np.asarray(all_labeled)\n",
    "        pred_set= np.concatenate(all_preds_arr, axis=0)\n",
    "\n",
    "        LABELS = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"] \n",
    "\n",
    "        \"\"\"\n",
    "        ####RECLASSIFYING TO THREE CLASSES ## if you want to reclassify the Mixed bare class/ Low vegetation sub-classes \n",
    "        gts_set=reclass_preds(gts_set,3,3)\n",
    "        pred_set=reclass_preds(pred_set,3,3)\n",
    "        LABELS = [\"1\",\"2\",\"3\"] \n",
    "        \"\"\"\n",
    "\n",
    "        ####CONFUSION MATRIX\n",
    "        #cm=confusion_matrix(gts_set, pred_set)\n",
    "\n",
    "        cm=confusion_matrix(gts_set, pred_set)\n",
    "\n",
    "        messagetoprint = \"Confusion matrix:\\n%s\" %cm\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        #OVERALL ACCURACY\n",
    "\n",
    "        messagetoprint=\"overall accuracy: %f\" %metrics.accuracy_score(gts_set, pred_set)\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ##TOTAL NUMBER OF PIXELS PROCESSED\n",
    "\n",
    "        total = sum(sum(cm))\n",
    "        messagetoprint = \"total number of pixels processed:\\n%s\" %total\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ###PRECISION AND RECALL\n",
    "        messagetoprint=\"Classification report:\\n\\n%s\" %metrics.classification_report(gts_set, \n",
    "                                            pred_set,\n",
    "                                            target_names=LABELS)\n",
    "        #print (messagetoprint)\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ####PRODUCER AND USER ACCURACY\n",
    "\n",
    "        PA = [cm[x][x]/np.sum(cm[x,:]) for x in range(len(cm))]\n",
    "\n",
    "        UA = [cm[x][x]/np.sum(cm[:,x]) for x in range(len(cm))]\n",
    "\n",
    "        PA_rounded = list(np.around(np.array(PA),4))\n",
    "        PA_dict={k: v for k, v in zip(LABELS, PA_rounded)}\n",
    "        messagetoprint=\"PRODUCER ACCURACY:\\n%s\" %PA_dict\n",
    "        txtcontent+=messagetoprint+\"\\n\"\n",
    "\n",
    "        UA_rounded=list(np.around(np.array(UA),4))\n",
    "        UA_dict={k: v for k, v in zip(LABELS, UA_rounded)}\n",
    "        messagetoprint=\"USER ACCURACY:\\n%s\" %UA_dict\n",
    "        txtcontent+=messagetoprint+\"\\n\"\n",
    "\n",
    "        f = open(logs_folder+\"/accuracy_metrics.txt\", 'w')\n",
    "        f.write(EXPT_ID+\" metrics\"+\"\\n\\n\")\n",
    "        f.write(txtcontent)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "        # FOR THE SECOND TILE\n",
    "\n",
    "        root_path = \"H:/DRC_THESIS/DNN_LABELLED_DATA/goma_prel_test_25_11\"\n",
    "\n",
    "        raw_files_pan = glob.glob(root_path+'/raw_tif_totest/*.tif')\n",
    "        mini_preds_folder = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/predictions/MINI_TILES\"\n",
    "        probs_folder = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/probabilities/WHOLE_TILE_PROBS\"\n",
    "\n",
    "        make_dir_paths(probs_folder)\n",
    "        make_dir_paths(mini_preds_folder)\n",
    "\n",
    "\n",
    "        ## TEST MODEL\n",
    "        t0 = time.time()\n",
    "\n",
    "        dom_net= UNET()\n",
    "        dom_net.load_state_dict(torch.load(w8_fname))\n",
    "        #dom_net = dom_net.classifier\n",
    "\n",
    "        for rgbn in raw_files_pan[:]:\n",
    "            rgbn_raw=img_to_array(rgbn)\n",
    "            geo_info,projec_info=data_proj(rgbn)\n",
    "\n",
    "            #normalize the rgb\n",
    "            rgbn_norm=norm_rgbn(rgbn_raw[0],gmax,gmin)\n",
    "            del rgbn_raw\n",
    "            #rgbn_norm = swap_a(rgbn_norm)\n",
    "\n",
    "            allpred= test(dom_net,[rgbn_norm],nc,stride=STRIDE)\n",
    "\n",
    "            file_name=os.path.split(rgbn)[-1]\n",
    "            save_to_1band(allpred[0][0]+1,mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_prob_1band(allpred[0][0],mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_to_1band(allpred[0][0]+1,mini_preds_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "            #save_prob_1band(allpred[1][0],probs_folder+\"/\"+file_name,geo_info,projec_info)\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(\"Finished testing after %.2f mins\" % ((t1-t0)/60.0))\n",
    "\n",
    "\n",
    "        #COMPUTE THE ACCURACY METRICS\n",
    "\n",
    "        txtcontent = \"\"\n",
    "\n",
    "        logs_folder=root_path+\"/RESULTS_METRICS_6CLASSES/\"+EXPT_ID+\"/FIGURES_TIME_LOGS\"\n",
    "        make_dir_paths(logs_folder)\n",
    "\n",
    "        class_path = root_path+\"/DOMAIN_ADAPT/RESULTS/\"+EXPT_ID+\"/predictions/MINI_TILES\"\n",
    "        #gts_files = glob.glob(root_path+\"/gts_tif_totest/*.tif\")\n",
    "        gts_files = glob.glob(root_path+\"/gts_tif2_test/*.tif\")\n",
    "        class_files= glob.glob(class_path+'/*.tif')\n",
    "\n",
    "        t0 = time.time()\n",
    "        num_tiles=len(gts_files)\n",
    "        counter = 0\n",
    "        all_gts=[]\n",
    "        all_labeled=[]\n",
    "\n",
    "        for gts,classified in zip(gts_files,class_files):\n",
    "            counter += 1\n",
    "            print(\"Tile %i of %i\" % (counter, num_tiles))\n",
    "            #importing the rasters\n",
    "            refs,labeled= img_to_array(gts,classified)\n",
    "\n",
    "            #reshape reference\n",
    "            refs = np.reshape (refs,(refs.shape[0],refs.shape[1]))\n",
    "            #reshape labels\n",
    "            labeled = np.reshape(labeled,(labeled.shape[0],labeled.shape[1]))\n",
    "\n",
    "            #idxarray = sample_idx_freq(refs,cratios,n) #\n",
    "            idxarray = sample_idx(refs) #\n",
    "\n",
    "            #extract the gts pixels into an array\n",
    "            idx_gts= extract_values(refs,idxarray)\n",
    "\n",
    "            #extract the pred pixels into an array\n",
    "            idx_pred=extract_values(labeled,idxarray)\n",
    "\n",
    "            #trainset=trainset[rand_list]\n",
    "            all_gts.append(idx_gts)\n",
    "            all_labeled.append(idx_pred)\n",
    "\n",
    "        #saving    \n",
    "        all_gts_arr=np.asarray(all_gts)\n",
    "        gts_set= np.concatenate(all_gts, axis=0)\n",
    "\n",
    "        all_preds_arr=np.asarray(all_labeled)\n",
    "        pred_set= np.concatenate(all_preds_arr, axis=0)\n",
    "\n",
    "        LABELS = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"] \n",
    "\n",
    "        \"\"\"\n",
    "        ####RECLASSIFYING TO THREE CLASSES ## if you want to reclassify the Mixed bare class/ Low vegetation sub-classes \n",
    "        gts_set=reclass_preds(gts_set,3,3)\n",
    "        pred_set=reclass_preds(pred_set,3,3)\n",
    "        LABELS = [\"1\",\"2\",\"3\"] \n",
    "        \"\"\"\n",
    "\n",
    "        ####CONFUSION MATRIX\n",
    "        #cm=confusion_matrix(gts_set, pred_set)\n",
    "\n",
    "        cm=confusion_matrix(gts_set, pred_set)\n",
    "\n",
    "        messagetoprint = \"Confusion matrix:\\n%s\" %cm\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        #OVERALL ACCURACY\n",
    "\n",
    "        messagetoprint=\"overall accuracy: %f\" %metrics.accuracy_score(gts_set, pred_set)\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ##TOTAL NUMBER OF PIXELS PROCESSED\n",
    "\n",
    "        total = sum(sum(cm))\n",
    "        messagetoprint = \"total number of pixels processed:\\n%s\" %total\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ###PRECISION AND RECALL\n",
    "        messagetoprint=\"Classification report:\\n\\n%s\" %metrics.classification_report(gts_set, \n",
    "                                            pred_set,\n",
    "                                            target_names=LABELS)\n",
    "        #print (messagetoprint)\n",
    "        txtcontent+=messagetoprint+\"\\n\\n\"\n",
    "\n",
    "        ####PRODUCER AND USER ACCURACY\n",
    "\n",
    "        PA = [cm[x][x]/np.sum(cm[x,:]) for x in range(len(cm))]\n",
    "\n",
    "        UA = [cm[x][x]/np.sum(cm[:,x]) for x in range(len(cm))]\n",
    "\n",
    "        PA_rounded = list(np.around(np.array(PA),4))\n",
    "        PA_dict={k: v for k, v in zip(LABELS, PA_rounded)}\n",
    "        messagetoprint=\"PRODUCER ACCURACY:\\n%s\" %PA_dict\n",
    "        txtcontent+=messagetoprint+\"\\n\"\n",
    "\n",
    "        UA_rounded=list(np.around(np.array(UA),4))\n",
    "        UA_dict={k: v for k, v in zip(LABELS, UA_rounded)}\n",
    "        messagetoprint=\"USER ACCURACY:\\n%s\" %UA_dict\n",
    "        txtcontent+=messagetoprint+\"\\n\"\n",
    "\n",
    "        f = open(logs_folder+\"/accuracy_metrics.txt\", 'w')\n",
    "        f.write(EXPT_ID+\" metrics\"+\"\\n\\n\")\n",
    "        f.write(txtcontent)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
